{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracting Satellite Images.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/fescobar96/Tracking-Water-Levels-in-Satellite-Data/blob/master/Extracting_Satellite_Images.ipynb",
      "authorship_tag": "ABX9TyPVydiZ5jLwCxZZf3diKeGw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyQ-9mFGc3js",
        "colab_type": "code",
        "outputId": "5c914e6c-9609-4e88-c1a0-f77df6695e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install sentinelsat\n",
        "!pip install geopandas\n",
        "!pip install rasterio\n",
        "!pip install pycrs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentinelsat\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/79/c2ac7b71dd13db95a9b83865bbbc7f1e4359c2b141bedad21b0e181fa06e/sentinelsat-0.13-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from sentinelsat) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sentinelsat) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sentinelsat) (7.1.2)\n",
            "Collecting geomet\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/81/156ca48f950f833ddc392f8e3677ca50a18cb9d5db38ccb4ecea55a9303f/geomet-0.2.1.post1-py3-none-any.whl\n",
            "Collecting html2text\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/88/14655f727f66b3e3199f4467bafcc88283e6c31b562686bf606264e09181/html2text-2020.1.16-py3-none-any.whl\n",
            "Collecting geojson>=2\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/8d/9e28e9af95739e6d2d2f8d4bef0b3432da40b7c3588fbad4298c1be09e48/geojson-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentinelsat) (4.38.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelsat) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelsat) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelsat) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelsat) (2020.4.5.1)\n",
            "Installing collected packages: geomet, html2text, geojson, sentinelsat\n",
            "Successfully installed geojson-2.5.0 geomet-0.2.1.post1 html2text-2020.1.16 sentinelsat-0.13\n",
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/c5/3cf9cdc39a6f2552922f79915f36b45a95b71fd343cfc51170a5b6ddb6e8/geopandas-0.7.0-py2.py3-none-any.whl (928kB)\n",
            "\u001b[K     |████████████████████████████████| 931kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.0.3)\n",
            "Collecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/20/4e63bc5c6e62df889297b382c3ccd4a7a488b00946aaaf81a118158c6f09/Fiona-1.8.13.post1-cp36-cp36m-manylinux1_x86_64.whl (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 308kB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/37/705ee471f71130d4ceee41bbcb06f3b52175cb89273cbb5755ed5e6374e0/pyproj-2.6.0-cp36-cp36m-manylinux2010_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 61.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (19.3.0)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.12.0)\n",
            "Installing collected packages: cligj, munch, click-plugins, fiona, pyproj, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.5.0 fiona-1.8.13.post1 geopandas-0.7.0 munch-2.5.0 pyproj-2.6.0\n",
            "Collecting rasterio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/81/13321f88f582a00705c5f348724728e8999136e19d6e7c56f7e6ac9bb7f9/rasterio-1.1.3-cp36-cp36m-manylinux1_x86_64.whl (18.1MB)\n",
            "\u001b[K     |████████████████████████████████| 18.1MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from rasterio) (19.3.0)\n",
            "Collecting affine\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/a6/1a39a1ede71210e3ddaf623982b06ecfc5c5c03741ae659073159184cd3e/affine-2.3.0-py2.py3-none-any.whl\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from rasterio) (0.5.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rasterio) (1.18.3)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.6/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n",
            "Installing collected packages: affine, snuggs, rasterio\n",
            "Successfully installed affine-2.3.0 rasterio-1.1.3 snuggs-1.4.7\n",
            "Collecting pycrs\n",
            "  Downloading https://files.pythonhosted.org/packages/50/0b/33c6ab39701d982eabfdc732d920862d79d7598893c7291c5f6ec1e66d3c/PyCRS-1.0.2.tar.gz\n",
            "Building wheels for collected packages: pycrs\n",
            "  Building wheel for pycrs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycrs: filename=PyCRS-1.0.2-cp36-none-any.whl size=32683 sha256=cea482f3308d1a31ac31c5703f646e0d33d860902475c7f1134897ed44ac5abc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/c9/56/648f762bd41fdb03454be51b8a7069795925168833cb61f316\n",
            "Successfully built pycrs\n",
            "Installing collected packages: pycrs\n",
            "Successfully installed pycrs-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebTc0-KFc9FL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "from sentinelsat import SentinelAPI\n",
        "import folium\n",
        "import shapely\n",
        "from shapely.geometry import MultiPolygon\n",
        "from shapely.geometry import Polygon\n",
        "from shapely.geometry import shape\n",
        "from shapely.geometry import box\n",
        "from shapely.ops import cascaded_union\n",
        "import urllib.request as request\n",
        "import json\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import zipfile\n",
        "import rasterio as rio\n",
        "from rasterio.plot import show\n",
        "from rasterio.mask import mask\n",
        "import os\n",
        "from fiona.crs import from_epsg\n",
        "from skimage import exposure\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import pycrs\n",
        "import shutil\n",
        "import time\n",
        "import PIL.ImageDraw as ImageDraw\n",
        "import PIL.Image as Image\n",
        "import imageio\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx93UNAZeDQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://water.blue-dot-observatory.com/api/waterbodies/'\n",
        "water_body_data = json.loads(request.urlopen(url).read().decode())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NioAWateJ1V",
        "colab_type": "code",
        "outputId": "dca43755-ac05-4ae3-cf27-cb2c721d79b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total = len(water_body_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSc8MQHjOx39",
        "colab_type": "text"
      },
      "source": [
        "Get downloaded ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gy43lNQXTCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_downloaded():\n",
        "  downloaded = []\n",
        "  for file in os.listdir('/content/drive/My Drive/Water Bodies Satellite Images/Images'):\n",
        "    idx = file.split('_')[2]\n",
        "    idx = idx.split('.')[0]\n",
        "    downloaded.append(idx)\n",
        "  return downloaded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqYigNIWYfmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "720d64de-57d0-4553-916c-c8d7d02e600b"
      },
      "source": [
        "check_downloaded()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C04OK_aNj52C",
        "colab_type": "text"
      },
      "source": [
        "Extract Geometries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH4hK_F1dD-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_geometries(max_records):\n",
        "  current_record = 18290\n",
        "  names = []\n",
        "  countries = []\n",
        "  latitudes = []\n",
        "  longitudes = []\n",
        "  geometries = []\n",
        "  idxs = []\n",
        "  while len(names) < max_records:\n",
        "    water_url = f'https://water.blue-dot-observatory.com/api/waterbodies/{current_record}/index.html'\n",
        "    try:\n",
        "      water_body_data = json.loads(request.urlopen(water_url).read().decode())\n",
        "      names.append(water_body_data['properties']['name'])\n",
        "      countries.append(water_body_data['properties']['country'])\n",
        "      latitudes.append(water_body_data['properties']['lat'])\n",
        "      longitudes.append(water_body_data['properties']['long'])\n",
        "      geometries.append(water_body_data['nominal_outline']['geometry'])\n",
        "      idxs.append(water_body_data['properties']['id'])\n",
        "    except:\n",
        "      pass\n",
        "    current_record += 1\n",
        "      \n",
        "  #Create Dataframe\n",
        "  water_bodies = pd.DataFrame({'Name':names,\n",
        "                             'Country':countries,\n",
        "                             'Latitude':latitudes,\n",
        "                             'Longitude':longitudes,\n",
        "                             'Geometry':geometries,\n",
        "                             'id':idxs})\n",
        "  water_bodies.to_csv('/content/drive/My Drive/Water Bodies Satellite Images/water_bodies.csv', encoding='utf-8', index=False)\n",
        "  \n",
        "  return water_bodies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNeqUVM2j4PW",
        "colab_type": "text"
      },
      "source": [
        "Download from satellite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECLmJtzEflrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_from_satellite(i, df):\n",
        "  #Create simple shape\n",
        "  water_body_geometry = df.iloc[i]['Geometry']\n",
        "  water_body_shape = shape(water_body_geometry)\n",
        "  shape_simplified = box(water_body_shape.bounds[0], water_body_shape.bounds[1], water_body_shape.bounds[2], water_body_shape.bounds[3])\n",
        "\n",
        "  #Download data\n",
        "  today = datetime.today()\n",
        "  one_year_ago = today - timedelta(days=365)\n",
        "  today = today.strftime('%Y%m%d')\n",
        "  results = api.query(shape_simplified, date = (one_year_ago, today), platformname = 'Sentinel-2', processinglevel = 'Level-1C', cloudcoverpercentage = (0,5))\n",
        "  results_gdf = api.to_geodataframe(results).sort_values(['cloudcoverpercentage'], ascending=True)\n",
        "  uuid = results_gdf.iloc[0]['uuid']\n",
        "  filename = '/content/' + results_gdf.iloc[0]['title'] + '.zip'\n",
        "  data = api.download(uuid)\n",
        "\n",
        "  #Extract data\n",
        "  with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/My Drive/Satellite Data/')\n",
        "  folder = os.listdir('/content/drive/My Drive/Satellite Data/' + data['title'] + '.SAFE/GRANULE/')[0]\n",
        "  directory = '/content/drive/My Drive/Satellite Data/' + data['title'] + '.SAFE/GRANULE/' + folder + '/IMG_DATA/'\n",
        "\n",
        "  #Delete ZIP file\n",
        "  os.remove(filename)\n",
        "\n",
        "  return directory, shape_simplified"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovmvsMqNkgzz",
        "colab_type": "text"
      },
      "source": [
        "Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhpLX4W9j2Ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_processing(directory, shape_simplified, output_directory, i):\n",
        "  main_directory = output_directory\n",
        "  output_directory = output_directory + 'Images'\n",
        "  #Open individual RGB bands\n",
        "  for f in os.listdir(directory):\n",
        "    if '_B02' in f:\n",
        "      band_2 = rio.open(directory + f)\n",
        "      with rio.open(directory + f) as src:\n",
        "        b2 = src.read(1)\n",
        "    elif '_B03' in f:\n",
        "      band_3 = rio.open(directory + f)\n",
        "      with rio.open(directory + f) as src:\n",
        "        b3 = src.read(1)\n",
        "    elif '_B04' in f:\n",
        "      band_4 = rio.open(directory + f)\n",
        "      with rio.open(directory + f) as src:\n",
        "        b4 = src.read(1)\n",
        "  \n",
        "  #Save complete image\n",
        "  with rio.open('RGB.tiff','w',driver='Gtiff', width=band_4.width, height=band_4.height, count=3,crs=band_4.crs,transform=band_4.transform, dtype=band_4.dtypes[0]) as rgb:\n",
        "    rgb.write(band_4.read(1),1) \n",
        "    rgb.write(band_3.read(1),2) \n",
        "    rgb.write(band_2.read(1),3) \n",
        "    rgb.close()\n",
        "\n",
        "  #Clip image\n",
        "  geo = gpd.GeoDataFrame({'geometry': shape_simplified}, index=[0], crs=from_epsg(4326))\n",
        "  src = rio.open('/content/RGB.tiff')\n",
        "  geo = geo.to_crs(crs=src.crs.data)\n",
        "  coordinates = [json.loads(geo.to_json())['features'][0]['geometry']]\n",
        "  out_img, out_transform = mask(dataset=src, shapes=coordinates, crop=True)\n",
        "  out_meta = src.meta.copy()\n",
        "  epsg_code = int(src.crs.data['init'][5:])\n",
        "  out_meta.update({\"driver\": \"GTiff\",\n",
        "                 \"height\": out_img.shape[1],\n",
        "                 \"width\": out_img.shape[2],\n",
        "                 \"transform\": out_transform,\n",
        "                 #\"crs\": pycrs.parse.from_epsg_code(epsg_code).to_proj4()\n",
        "                 }\n",
        "                         )\n",
        "  with rio.open('/content/output.tiff', \"w\", **out_meta) as dest:\n",
        "    dest.write(out_img)\n",
        "  \n",
        "  #Normalize and merge color bands\n",
        "  img = rio.open('output.tiff')\n",
        "  image = np.array([img.read(1), img.read(2), img.read(3)]).transpose(1,2,0)\n",
        "  p2, p98 = np.percentile(image, (2,98))\n",
        "  image = exposure.rescale_intensity(image, in_range=(p2, p98)) / 100000\n",
        "  output_filename = output_directory + '/water_body_' + str(water_bodies['id'][i]) + '.jpg'\n",
        "  matplotlib.image.imsave(output_filename, image)\n",
        "\n",
        "  return output_filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJR9jb7YnFum",
        "colab_type": "text"
      },
      "source": [
        "Delete raster files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpOQnZI0nFDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delete_trash():\n",
        "  for trash in os.listdir('/content/drive/My Drive/Satellite Data/'):\n",
        "    shutil.rmtree('/content/drive/My Drive/Satellite Data/' + trash)\n",
        "\n",
        "  os.remove('/content/NDWI.tif')\n",
        "  os.remove('/content/RGB.tiff')\n",
        "  os.remove('/content/output.tiff')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stIV4fICrPfp",
        "colab_type": "text"
      },
      "source": [
        "Create mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BlIL4hdxcqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mask(directory, output_directory, i):\n",
        "  output_directory = output_directory + 'Masks'\n",
        "  #Create mask\n",
        "  for f in os.listdir(directory):\n",
        "    if '_B03' in f:\n",
        "      with rio.open(directory + f) as src:\n",
        "        b3 = src.read(1)\n",
        "    elif '_B08' in f:\n",
        "      with rio.open(directory + f) as src:\n",
        "        b8 = src.read(1)\n",
        "  NDWI = (b8.astype(float) - b3.astype(float)) / (b8 + b3)\n",
        "  out_meta = src.meta\n",
        "  out_meta.update(driver = 'GTiff', dtype=rio.float32, count = 1)\n",
        "  with rio.open('NDWI.tif', 'w', **out_meta) as dst:\n",
        "    dst.write_band(1, NDWI.astype(rio.float32))\n",
        "  src = rio.open(\"NDWI.tif\")\n",
        "\n",
        "  water_body_shape = shape(water_bodies.iloc[i]['Geometry'])\n",
        "  polygons = [water_body_shape]\n",
        "  boundary = gpd.GeoSeries(cascaded_union(polygons))\n",
        "  geo = gpd.GeoDataFrame({'geometry': boundary}, index=[0], crs=from_epsg(4326))\n",
        "\n",
        "  geo = geo.to_crs(crs=src.crs.data)\n",
        "  coordinates = [json.loads(geo.to_json())['features'][0]['geometry']]\n",
        "  out_img, out_transform = mask(dataset=src, shapes=coordinates, crop=True)\n",
        "  out_meta = src.meta.copy()\n",
        "  epsg_code = int(src.crs.data['init'][5:])\n",
        "  out_meta.update({\"driver\": \"GTiff\",\n",
        "                 \"height\": out_img.shape[1],\n",
        "                 \"width\": out_img.shape[2],\n",
        "                 \"transform\": out_transform,\n",
        "                 \"crs\": pycrs.parse.from_epsg_code(epsg_code).to_proj4()\n",
        "                 }\n",
        "                         )\n",
        "  with rio.open('/content/output.tiff', \"w\", **out_meta) as dest:\n",
        "    dest.write(out_img)\n",
        "\n",
        "  #Normalize and merge color bands\n",
        "  img = rio.open('output.tiff')\n",
        "  image = np.array([img.read(1)])\n",
        "  p2, p98 = np.percentile(image, (2,98))\n",
        "  image = exposure.rescale_intensity(image, in_range=(p2, p98)) / 100000\n",
        "  image[image>0] = 1\n",
        "  output_filename = output_directory + '/water_body_' + str(water_bodies['id'][i]) + '.jpg'\n",
        "  image = np.rollaxis(image, 0, 3)\n",
        "  image = np.squeeze(image,axis=2)\n",
        "  image = 1 - image\n",
        "  matplotlib.image.imsave(output_filename, image, cmap='Greys_r')\n",
        "  return output_filename\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64AcgKl_iFJQ",
        "colab_type": "text"
      },
      "source": [
        "Complete Workflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpdWnU0PiI4L",
        "colab_type": "code",
        "outputId": "08e87bb8-9135-4e0f-aab9-a76b768cae6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "output_directory = '/content/drive/My Drive/Water Bodies Satellite Images/'\n",
        "\n",
        "#Extract geometries and create dataframe\n",
        "water_bodies = extract_geometries(total)\n",
        "\n",
        "#Check downloaded ids\n",
        "downloaded = check_downloaded()\n",
        "\n",
        "#Log in to Sentinel Hub\n",
        "with open('/content/drive/My Drive/Sentinel Hub Credentials/login_info.txt') as file:\n",
        "  credentials = file.readlines()\n",
        "  credentials = [credential.strip() for credential in credentials]\n",
        "api = SentinelAPI(credentials[0], credentials[1], 'https://scihub.copernicus.eu/dhus')\n",
        "\n",
        "#Download and unzipe file\n",
        "t0 = time.time()\n",
        "for i in range(0, len(water_bodies)):\n",
        "  #if str(water_bodies['id'][i]) not in downloaded:\n",
        "    #Calculate ETA\n",
        "    t1 = time.time()\n",
        "    if i != 0 :\n",
        "      total = round((t2 - t0)/60,2)\n",
        "      eta = round(total/(i) * (len(water_bodies)-i))\n",
        "    else:\n",
        "      eta = 'N/A'\n",
        "      total = 'N/A'\n",
        "\n",
        "    name = water_bodies.iloc[i]['Name']\n",
        "    country = water_bodies.iloc[i]['Country']\n",
        "    print(f'Image {i+1} of {len(water_bodies)}: {name}, {country}. ETA: {eta} min. Total: {total} min.')\n",
        "    directory, shape_simplified = download_from_satellite(i, water_bodies)\n",
        "\n",
        "    #Clip image, merge and normalize color bands\n",
        "    output_filename = image_processing(directory, shape_simplified, output_directory, i)\n",
        "\n",
        "    #Create mask\n",
        "    output_mask = create_mask(directory, output_directory, i)\n",
        "\n",
        "    #Delete raster files\n",
        "    delete_trash()\n",
        "\n",
        "    #Rotate and resize image\n",
        "    image_1 = Image.open(output_filename)\n",
        "    image_2 = Image.open(output_mask)\n",
        "    x = (image_1.size[0] - image_2.size[0])//2\n",
        "    y = (image_1.size[1] - image_2.size[1])//2\n",
        "    image_1_crop = image_1.crop((x, y, image_2.size[0]+x, image_2.size[1]+y))\n",
        "    image_1_crop.save(output_filename)\n",
        "\n",
        "    t2 = time.time()\n",
        "    print('\\n')\n",
        "  #else:\n",
        "    idx = water_bodies['id'][i]\n",
        "    print(f'ID:{idx} already downloaded')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image 1 of 1: Lake Travis, United States of America. ETA: N/A min. Total: N/A min.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 869M/869M [01:20<00:00, 10.8MB/s]\n",
            "MD5 checksumming: 100%|██████████| 869M/869M [00:01<00:00, 463MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "ID:18290 already downloaded\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}